# coding:utf-8"""__file__    combine_feat.py__description__    This file provides modules for combining features and save them in svmlight format.__author__    Chenglong Chen < c.chenglong@gmail.com >"""import osimport cPickleimport numpy as npimport pandas as pdfrom sklearn.base import BaseEstimatorfrom sklearn.datasets import dump_svmlight_filefrom scipy.sparse import hstackimport competition.conf.model_params_conf as configimport competition.feat.conf.LSA_and_stats_feat_Jun09_Low as LSA_and_stats_feat_Jun09_Lowimport competition.feat.conf.LSA_svd150_and_Jaccard_coef_Jun14_Low as LSA_svd150_and_Jaccard_coef_Jun14_Lowimport competition.feat.conf.svd100_and_bow_Jun23_Low as svd100_and_bow_Jun23_Lowimport competition.feat.conf.svd100_and_bow_Jun27_High as svd100_and_bow_Jun27_High# adopted from @Ben Hamner's Python Benchmark code# https://www.kaggle.com/benhamner/crowdflower-search-relevance/python-benchmarkdef identity(x):    return xclass SimpleTransform(BaseEstimator):    def __init__(self, transformer=identity):        self.transformer = transformer    def fit(self, X, y=None):        return self    def fit_transform(self, X, y=None):        return self.transform(X)    def transform(self, X, y=None):        return self.transformer(X)def gen_feat(single_feat_path, combined_feat_path, feat_names, mode):    """    :param single_feat_path:    :param combined_feat_path:    :param feat_names:    :param mode    :return:    """    if not os.path.exists(combined_feat_path):        os.makedirs(combined_feat_path)    for i, (feat_name, transformer) in enumerate(feat_names):        ## load train feat        feat_train_file = "%s/train.%s.feat.pkl" % (single_feat_path, feat_name)        with open(feat_train_file, "rb") as f:            x_train = cPickle.load(f)        if len(x_train.shape) == 1:            x_train.shape = (x_train.shape[0], 1)        ## load test feat        feat_test_file = "%s/%s.%s.feat.pkl" % (single_feat_path, mode, feat_name)        with open(feat_test_file, "rb") as f:            x_test = cPickle.load(f)        if len(x_test.shape) == 1:            x_test.shape = (x_test.shape[0], 1)        ## align feat dim 补齐列？matrix hstack  tocsr 稀疏格式        dim_diff = abs(x_train.shape[1] - x_test.shape[1])        if x_test.shape[1] < x_train.shape[1]:            x_test = hstack([x_test, np.zeros((x_test.shape[0], dim_diff))]).tocsr()        elif x_test.shape[1] > x_train.shape[1]:            x_train = hstack([x_train, np.zeros((x_train.shape[0], dim_diff))]).tocsr()        ## apply transformation        x_train = transformer.fit_transform(x_train)        x_test = transformer.transform(x_test)        ## stack feat 多个属性列组合在一起        if i == 0:            X_train, X_test = x_train, x_test        else:            try:                X_train, X_test = hstack([X_train, x_train]), hstack([x_test, x_test])            except:                X_train, X_test = np.hstack([X_train, x_train]), np.hstack([x_test, x_test])        # > 右对齐 自动填充{}        print("Combine {:>2}/{:>2} feat: {} ({}D)".format(i + 1, len(feat_names), feat_name, x_train.shape[1]))    print "Feat dim: {}D".format(X_train.shape[1])    # train info 中获取label值    info_train = pd.read_csv("%s/train.info" % (combined_feat_path))    # change it to zero-based for multi-classification in xgboost    Y_train = info_train["median_relevance"] - 1    # test    info_test = pd.read_csv("%s/%s.info" % (combined_feat_path, mode))    Y_test = info_test["median_relevance"] - 1    # dump feat 生成所有的特征+label    dump_svmlight_file(X_train, Y_train, "%s/train.feat" % (combined_feat_path))    dump_svmlight_file(X_test, Y_test, "%s/%s.feat" % (combined_feat_path, mode))#### function to combine featuresdef combine_feat(feat_names, feat_path_name):    print("==================================================")    print("Combine features...")    # Cross-validation    print("For cross-validation...")    ## for each run and fold  把没Run每折train.%s.feat.pkl　文件读出来合并到一起　然后保存到    for run in range(1, config.n_runs + 1):        # use 33% for training and 67 % for validation, so we switch trainInd and validInd        for fold in range(1, config.n_folds + 1):            print("Run: %d, Fold: %d" % (run, fold))            # 单个feat path            path = "%s/Run%d/Fold%d" % (config.feat_folder, run, fold)            # 合并后的feat path            save_path = "%s/%s/Run%d/Fold%d" % (config.feat_folder, feat_path_name, run, fold)            gen_feat(path, save_path, feat_names, "valid")    # Training and Testing    print("For training and testing...")    path = "%s/All" % (config.feat_folder)    save_path = "%s/%s/All" % (config.feat_folder, feat_path_name)    gen_feat(path, save_path, feat_names, "valid")if __name__ == "__main__":    """    生成所有的特征+label    """    combine_feat(LSA_and_stats_feat_Jun09_Low.feat_names, feat_path_name="LSA_and_stats_feat_Jun09")    combine_feat(LSA_svd150_and_Jaccard_coef_Jun14_Low.feat_names, feat_path_name="LSA_svd150_and_Jaccard_coef_Jun14")    combine_feat(svd100_and_bow_Jun23_Low.feat_names, feat_path_name="svd100_and_bow_Jun23")    combine_feat(svd100_and_bow_Jun27_High.feat_names, feat_path_name="svd100_and_bow_Jun27")